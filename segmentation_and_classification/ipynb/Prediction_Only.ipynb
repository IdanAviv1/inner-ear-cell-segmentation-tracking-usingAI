{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8NfhDNOMYnp",
        "outputId": "3ea45d72-2965-474c-98bc-f30cd34c2952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from: /content/drive/MyDrive/Final_Project/experiments/exp_19_Full_Data_set/model_epoch_10.h5\n",
            "âœ… Weights loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reading segmentation (black-skip only): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:13<00:00,  3.80it/s]\n",
            "Reading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:17<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ” Predicting 48 frames (non-black only)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [14:52<00:00, 18.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Saved multi-page TIF (with black frames reinserted) to: /content/drive/MyDrive/Final_Project/output_predictions/all_predictions.tif\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "U-Net Prediction Script (Export to multi-page TIFF)\n",
        "\n",
        "What it does\n",
        "------------\n",
        "- Loads a U-Net with your weights.\n",
        "- Reads a two-channel time-series TIFF (interleaved pages: ch1, ch2, ch1, ch2, ...).\n",
        "- Reads a GT TIFF (used ONLY to detect fully-black frames and keep index alignment).\n",
        "- Predicts segmentation for non-black frames, then reinserts black frames as all-zero\n",
        "  class maps at their original indices.\n",
        "- Exports a single multi-page TIFF of predictions with values {0, 85, 170, 255}\n",
        "  corresponding to classes {0, 1, 2, 3}.\n",
        "\n",
        "Requirements\n",
        "------------\n",
        "Python >= 3.9\n",
        "pip install numpy opencv-python tifffile tqdm tensorflow scipy\n",
        "\n",
        "Inputs you must set\n",
        "-------------------\n",
        "- MODEL_PATH:     path to your trained weights (compatible with the U-Net below).\n",
        "- DATA_TIF_PATH:  path to the data TIFF (interleaved ch1/ch2 pages).\n",
        "- LABEL_TIF_PATH: path to the GT TIFF (used only to detect black frames & keep alignment).\n",
        "- OUTPUT_DIR:     folder to write the predictions TIFF into.\n",
        "\n",
        "Outputs\n",
        "-------\n",
        "- OUTPUT_TIF_PATH = <OUTPUT_DIR>/all_predictions.tif\n",
        "  A multi-page TIFF with one page per frame (class map encoded as class_index * 85).\n",
        "  Black frames from the GT are present at their original indices as all-zero pages.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPool2D, Conv2DTranspose, Concatenate, BatchNormalization, Activation\n",
        ")\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =========================\n",
        "# USER CONFIG (EDIT THESE)\n",
        "# =========================\n",
        "MODEL_PATH     = \"model.h5\"                       # path to weights file\n",
        "DATA_TIF_PATH  = \"position.tif\"                   # data TIFF (interleaved ch1/ch2)\n",
        "LABEL_TIF_PATH = \"seg.tif\"                        # GT TIFF (only for black-frame indices)\n",
        "OUTPUT_DIR     = \"output_predictions\"             # output folder for predictions TIFF\n",
        "\n",
        "# Optional caps / behavior\n",
        "MAX_FRAMES_TO_EVAL = None   # None to use all frames; otherwise limit to first N frames\n",
        "TRANSPOSE_FIRST_N  = 1000   # apply cv2.transpose on the first N GT frames (to match your training convention)\n",
        "\n",
        "# =========================\n",
        "# DERIVED PATHS (no edit)\n",
        "# =========================\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "OUTPUT_TIF_PATH = os.path.join(OUTPUT_DIR, \"all_predictions.tif\")\n",
        "\n",
        "# =============================================================================\n",
        "# Helpers\n",
        "# =============================================================================\n",
        "def pad_image_to_multiple(image: np.ndarray, factor: int = 16):\n",
        "    \"\"\"\n",
        "    Pad spatial dimensions (H, W) up to a multiple of 'factor' using reflection.\n",
        "    Keeps channel dimension unchanged.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): input image of shape (H, W, C).\n",
        "        factor (int): target multiple for H and W.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - padded (np.ndarray): padded image (H', W', C).\n",
        "            - pad_h (int): number of bottom rows added.\n",
        "            - pad_w (int): number of rightmost cols added.\n",
        "    \"\"\"\n",
        "    h, w, _ = image.shape\n",
        "    pad_h = (factor - h % factor) if h % factor != 0 else 0\n",
        "    pad_w = (factor - w % factor) if w % factor != 0 else 0\n",
        "    padded = np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"reflect\")\n",
        "    return padded, pad_h, pad_w\n",
        "\n",
        "\n",
        "def unpad_prediction(pred: np.ndarray, pad_h: int, pad_w: int):\n",
        "    \"\"\"\n",
        "    Remove padding previously added by pad_image_to_multiple.\n",
        "\n",
        "    Args:\n",
        "        pred (np.ndarray): prediction of shape (H+pad_h, W+pad_w, num_classes).\n",
        "        pad_h (int): rows to remove from bottom.\n",
        "        pad_w (int): cols to remove from right.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: unpadded prediction of shape (H, W, num_classes).\n",
        "    \"\"\"\n",
        "    if pad_h > 0:\n",
        "        pred = pred[:-pad_h, :, :]\n",
        "    if pad_w > 0:\n",
        "        pred = pred[:, :-pad_w, :]\n",
        "    return pred\n",
        "\n",
        "\n",
        "def conv_block(inputs, num_filters: int):\n",
        "    \"\"\"\n",
        "    Two Conv2D -> BN -> ReLU layers with 'same' padding.\n",
        "\n",
        "    Args:\n",
        "        inputs: Keras tensor.\n",
        "        num_filters (int): filters for both conv layers.\n",
        "\n",
        "    Returns:\n",
        "        Keras tensor: processed features.\n",
        "    \"\"\"\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def encoder_block(inputs, num_filters: int):\n",
        "    \"\"\"\n",
        "    Encoder stage: conv_block + 2x2 MaxPool.\n",
        "\n",
        "    Args:\n",
        "        inputs: Keras tensor.\n",
        "        num_filters (int): filters in conv_block.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - skip: features (for skip connection).\n",
        "            - pooled: downsampled features.\n",
        "    \"\"\"\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "\n",
        "def decoder_block(inputs, skip, num_filters: int):\n",
        "    \"\"\"\n",
        "    Decoder stage: up-convolution -> concatenate skip -> conv_block.\n",
        "\n",
        "    Args:\n",
        "        inputs: decoder input tensor.\n",
        "        skip: encoder skip tensor to concatenate.\n",
        "        num_filters (int): filters in conv_block.\n",
        "\n",
        "    Returns:\n",
        "        Keras tensor: decoded features.\n",
        "    \"\"\"\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    \"\"\"\n",
        "    Build the U-Net segmentation model used for inference.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): e.g. (None, None, 2) for full-frame inference.\n",
        "\n",
        "    Returns:\n",
        "        tensorflow.keras.Model: U-Net with softmax over 4 classes.\n",
        "    \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "    b1 = conv_block(p4, 1024)\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "    outputs = Conv2D(4, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "\n",
        "def load_trained_model(model_path: str):\n",
        "    \"\"\"\n",
        "    Build U-Net and load weights from disk.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): path to weights (compatible with this architecture).\n",
        "\n",
        "    Returns:\n",
        "        tensorflow.keras.Model: ready for inference.\n",
        "    \"\"\"\n",
        "    print(f\"Loading weights from: {model_path}\")\n",
        "    model = build_unet((None, None, 2))\n",
        "    model.load_weights(model_path)\n",
        "    print(\"Weights loaded successfully.\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def normalize_channel(image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Percentile normalization after CLAHE+blur (applied earlier in the pipeline).\n",
        "    If dynamic range is degenerate, returns zeros.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): 2D array (uint8/float).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: float32 image in [0, 1].\n",
        "    \"\"\"\n",
        "    per99 = np.percentile(image, 99)\n",
        "    per1 = np.percentile(image, 1)\n",
        "    eps = 1e-6\n",
        "    if per99 - per1 < eps:\n",
        "        return np.zeros_like(image, dtype=np.float32)\n",
        "    image = np.clip(image, per1, per99)\n",
        "    return ((image - per1) / (per99 - per1)).astype(np.float32)\n",
        "\n",
        "\n",
        "def read_segmentation_frames(tiff_path: str, transpose_first_n: int = TRANSPOSE_FIRST_N, max_frames=None):\n",
        "    \"\"\"\n",
        "    Read GT TIFF pages (odd indices), detect fully-black frames, and apply 'undefined->3'.\n",
        "\n",
        "    NOTE: The returned GT is not used for metrics here; only black indices are used to\n",
        "    skip prediction and to reinsert black pages at the end.\n",
        "\n",
        "    Args:\n",
        "        tiff_path (str): path to GT TIFF.\n",
        "        transpose_first_n (int): apply cv2.transpose to the first N frames.\n",
        "        max_frames (int|None): cap the number of frames to read.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - y_true (np.ndarray): GT class maps (0..3) for non-black frames (kept for shape consistency).\n",
        "            - black_indices (list[int]): indices of fully-black frames.\n",
        "    \"\"\"\n",
        "    import tifffile as tiff\n",
        "    from scipy.ndimage import binary_dilation\n",
        "\n",
        "    def separate_undefined_regions(frame: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Mark 'undefined' background regions (0) far from cells (1/2) as class 3.\n",
        "        \"\"\"\n",
        "        frame = frame.copy()\n",
        "        zero_mask = (frame == 0)\n",
        "        cell_mask = (frame == 1) | (frame == 2)\n",
        "        dilated_cells = binary_dilation(cell_mask)\n",
        "        undefined_mask = zero_mask & (~dilated_cells)\n",
        "        frame[undefined_mask] = 3\n",
        "        return frame.astype(np.uint8)\n",
        "\n",
        "    y_true = []\n",
        "    black_indices = []\n",
        "    frame_counter = 0\n",
        "\n",
        "    with tiff.TiffFile(tiff_path) as tif:\n",
        "        all_indices = list(range(1, len(tif.pages), 2))  # GT pages at odd indices\n",
        "        if max_frames is not None:\n",
        "            all_indices = all_indices[:max_frames]\n",
        "\n",
        "        for _, i in tqdm(enumerate(all_indices), total=len(all_indices), desc=\"Reading GT (black-skip only)\"):\n",
        "            frame = tif.pages[i].asarray()\n",
        "            idx = frame_counter\n",
        "            if np.all(frame == 0):\n",
        "                black_indices.append(idx)\n",
        "                frame_counter += 1\n",
        "                continue\n",
        "            if idx < transpose_first_n:\n",
        "                frame = cv2.transpose(frame)\n",
        "            y_true.append(separate_undefined_regions(frame))\n",
        "            frame_counter += 1\n",
        "\n",
        "    return np.array(y_true), black_indices\n",
        "\n",
        "\n",
        "def read_data_frames(tiff_path: str, skip_indices=None, max_frames=None):\n",
        "    \"\"\"\n",
        "    Read data TIFF frames as interleaved pairs (ch1, ch2), apply CLAHE+blur+normalization,\n",
        "    and stack into (H, W, 2). Skips frames whose indices appear in 'skip_indices'.\n",
        "\n",
        "    Args:\n",
        "        tiff_path (str): path to data TIFF (interleaved channels).\n",
        "        skip_indices (Iterable[int]|None): frame indices to skip (e.g., black frames from GT).\n",
        "        max_frames (int|None): cap the number of frames to read.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: array of shape (N_non_skipped, H, W, 2), dtype float32.\n",
        "    \"\"\"\n",
        "    if skip_indices is None:\n",
        "        skip_indices = []\n",
        "\n",
        "    import tifffile as tiff\n",
        "\n",
        "    X_data = []\n",
        "    frame_counter = 0\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "\n",
        "    with tiff.TiffFile(tiff_path) as tif:\n",
        "        total_frames = len(tif.pages) // 2\n",
        "        num_frames = total_frames if max_frames is None else min(max_frames, total_frames)\n",
        "\n",
        "        for i in tqdm(range(num_frames), desc=\"Reading data\"):\n",
        "            if frame_counter in skip_indices:\n",
        "                frame_counter += 1\n",
        "                continue\n",
        "\n",
        "            ch1 = tif.pages[2 * i].asarray()\n",
        "            ch2 = tif.pages[2 * i + 1].asarray()\n",
        "\n",
        "            ch1 = clahe.apply(ch1)\n",
        "            ch2 = clahe.apply(ch2)\n",
        "            ch1 = cv2.GaussianBlur(ch1, (3, 3), 0)\n",
        "            ch2 = cv2.GaussianBlur(ch2, (3, 3), 0)\n",
        "\n",
        "            ch1 = normalize_channel(ch1)\n",
        "            ch2 = normalize_channel(ch2)\n",
        "\n",
        "            X_data.append(np.stack([ch1, ch2], axis=-1).astype(np.float32))\n",
        "            frame_counter += 1\n",
        "\n",
        "    return np.array(X_data)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Prediction + export with black-frame reinsertion\n",
        "# =============================================================================\n",
        "def run_prediction_and_save_tif():\n",
        "    \"\"\"\n",
        "    Full pipeline:\n",
        "        1) Load model and weights.\n",
        "        2) Read GT to collect black frame indices (and preserve alignment).\n",
        "        3) Read data frames, skipping black indices.\n",
        "        4) Predict per frame with padding-to-multiple-of-16 and unpadding.\n",
        "        5) Reinsert black frames as all-zero class maps at original indices.\n",
        "        6) Write a multi-page TIFF to OUTPUT_TIF_PATH with values {0,85,170,255}.\n",
        "    \"\"\"\n",
        "    import tifffile as tiff\n",
        "\n",
        "    model = load_trained_model(MODEL_PATH)\n",
        "    _, black_indices = read_segmentation_frames(\n",
        "        LABEL_TIF_PATH, transpose_first_n=TRANSPOSE_FIRST_N, max_frames=MAX_FRAMES_TO_EVAL\n",
        "    )\n",
        "    X_data = read_data_frames(\n",
        "        DATA_TIF_PATH, skip_indices=black_indices, max_frames=MAX_FRAMES_TO_EVAL\n",
        "    )\n",
        "\n",
        "    print(f\"\\nPredicting {len(X_data)} non-black frames...\")\n",
        "    y_pred_classes = []\n",
        "\n",
        "    for i in tqdm(range(len(X_data)), desc=\"Predicting\"):\n",
        "        img = X_data[i]\n",
        "        padded, pad_h, pad_w = pad_image_to_multiple(img)\n",
        "        pred = model.predict(np.expand_dims(padded, axis=0), verbose=0)[0]\n",
        "        unpadded = unpad_prediction(pred, pad_h, pad_w)\n",
        "        y_pred_classes.append(np.argmax(unpadded, axis=-1).astype(np.uint8))\n",
        "\n",
        "    # Reinsert black frames at original indices as all-zero class maps\n",
        "    num_black = len(black_indices)\n",
        "    total_frames = num_black + len(y_pred_classes)\n",
        "    black_set = set(black_indices)\n",
        "\n",
        "    # Determine output frame shape\n",
        "    if len(y_pred_classes) > 0:\n",
        "        H, W = y_pred_classes[0].shape\n",
        "    else:\n",
        "        # Fallback: read dimensions from the first odd GT page\n",
        "        import tifffile as tiff  # local import to match original pattern\n",
        "        with tiff.TiffFile(LABEL_TIF_PATH) as tif_gt:\n",
        "            sample = tif_gt.pages[1].asarray()\n",
        "            H, W = sample.shape\n",
        "\n",
        "    assembled = []\n",
        "    pred_ptr = 0\n",
        "    for idx in range(total_frames):\n",
        "        if idx in black_set:\n",
        "            assembled.append(np.zeros((H, W), dtype=np.uint8))\n",
        "        else:\n",
        "            assembled.append(y_pred_classes[pred_ptr])\n",
        "            pred_ptr += 1\n",
        "\n",
        "    # Encode classes as values {0,85,170,255} and save\n",
        "    stack = (np.stack(assembled, axis=0).astype(np.uint8) * 85).astype(np.uint8)  # (N, H, W)\n",
        "    tiff.imwrite(OUTPUT_TIF_PATH, stack)\n",
        "    print(f\"\\nSaved multi-page TIFF to: {OUTPUT_TIF_PATH}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_prediction_and_save_tif()\n"
      ]
    }
  ]
}